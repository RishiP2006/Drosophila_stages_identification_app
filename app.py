# app.py
import time, uuid
import streamlit as st
st.set_page_config(page_title="Drosophila Stage Identification", layout="centered")

# (Old components sometimes call experimental_rerun)
if not hasattr(st, "experimental_rerun") and hasattr(st, "rerun"):
    st.experimental_rerun = st.rerun  # type: ignore

import numpy as np
from PIL import Image, ImageDraw, ImageFont
from huggingface_hub import hf_hub_download
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase, WebRtcMode
import av

# Keras 3 runtime
from keras.models import load_model as k_load_model
from keras.applications.inception_v3 import preprocess_input

# â”€â”€ Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
HF_REPO_ID = "RishiPTrial/my-model-name"
MODEL_FILE = "drosophila_inceptionv3_classifier.h5"
INPUT_SIZE = 299
STAGE_LABELS = [
    "egg","1st instar","2nd instar","3rd instar","white pupa","brown pupa","eye pupa"
]

# Optional: use your own TURN via Twilio if secrets provided
def get_rtc_configuration():
    sid = st.secrets.get("TWILIO_ACCOUNT_SID")
    tok = st.secrets.get("TWILIO_AUTH_TOKEN")
    if sid and tok:
        # Minimal Twilio TURN (token generated by client lib endpoint); using static URLs here is fine for most cases
        return {
            "iceServers": [
                {"urls": ["stun:global.stun.twilio.com:3478"]},
                {"urls": ["turn:global.turn.twilio.com:3478?transport=udp",
                          "turn:global.turn.twilio.com:3478?transport=tcp",
                          "turn:global.turn.twilio.com:443?transport=tcp"],
                 "username": sid, "credential": tok}
            ]
        }
    # Default STUN only (no forced relay). This is the most robust baseline on Streamlit Cloud.
    return {"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]}

RTC_CONFIGURATION = get_rtc_configuration()

MEDIA_STREAM_CONSTRAINTS = {
    "video": {"width": {"ideal": 640}, "height": {"ideal": 480}, "frameRate": {"ideal": 15}},
    "audio": False,
}

# Stable key so the PeerConnection isnâ€™t recreated by reruns
if "webrtc_key" not in st.session_state:
    st.session_state["webrtc_key"] = f"live-{uuid.uuid4().hex}"

# â”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource(show_spinner="Loading model from Hugging Faceâ€¦")
def load_model():
    token = st.secrets.get("HF_TOKEN")
    path = hf_hub_download(repo_id=HF_REPO_ID, filename=MODEL_FILE, token=token)
    return k_load_model(path, compile=False)

model = load_model()

# â”€â”€ Helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def preprocess_image(pil: Image.Image) -> np.ndarray:
    pil = pil.resize((INPUT_SIZE, INPUT_SIZE)).convert("RGB")
    arr = np.asarray(pil, dtype=np.float32)
    return preprocess_input(arr)

def classify(pil: Image.Image):
    x = preprocess_image(pil)[np.newaxis]
    preds = model.predict(x, verbose=0)[0]
    idx = int(np.argmax(preds))
    return STAGE_LABELS[idx], float(preds[idx]), preds

def annotate(pil: Image.Image, text: str) -> Image.Image:
    out = pil.copy()
    d = ImageDraw.Draw(out)
    try:
        font = ImageFont.truetype("DejaVuSans-Bold.ttf", 28)
    except Exception:
        font = ImageFont.load_default()
    try:
        bbox = d.textbbox((0, 0), text, font=font)
        w, h = bbox[2]-bbox[0], bbox[3]-bbox[1]
    except Exception:
        w, h = d.textsize(text, font=font)
    pad = 6
    d.rectangle([0-pad, 0-pad, w+pad, h+pad], fill="black")
    d.text((0, 0), text, font=font, fill="red")
    return out

# â”€â”€ UI: Upload (works regardless of WebRTC) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.title("ðŸª° Drosophila Stage Identification")

st.markdown("### ðŸ“· Upload Image")
up = st.file_uploader("Upload a Drosophila image (JPG/PNG)", type=["jpg","jpeg","png"])
if up:
    pil = Image.open(up).convert("RGB")
    label, conf, probs = classify(pil)
    c1, c2 = st.columns(2)
    with c1:
        st.subheader("Prediction")
        st.write(f"**Stage:** {label}")
        st.write(f"**Confidence:** {conf:.2%}")
        with st.expander("Class probabilities"):
            for lab, p in sorted(zip(STAGE_LABELS, probs), key=lambda z: z[1], reverse=True):
                st.write(f"{lab}: {float(p):.2%}")
    with c2:
        st.subheader("Annotated")
        st.image(annotate(pil, f"{label} ({conf:.0%})"), use_column_width=True)

st.markdown("---")
st.subheader("ðŸ“¸ Live Camera Stage Detection")

# â”€â”€ Video processor (NO Streamlit calls here) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class StageProcessor(VideoProcessorBase):
    def __init__(self):
        try:
            self.font = ImageFont.truetype("DejaVuSans-Bold.ttf", 28)
        except Exception:
            self.font = ImageFont.load_default()
        self.last_infer_t = 0.0
        self.infer_interval_s = 0.35  # throttle a little

    def recv(self, frame: av.VideoFrame) -> av.VideoFrame:
        img = frame.to_ndarray(format="rgb24")
        pil = Image.fromarray(img)
        now = time.time()
        text = "â€¦"
        if now - self.last_infer_t >= self.infer_interval_s:
            self.last_infer_t = now
            label, conf, _ = classify(pil)
            text = f"{label} ({conf:.0%})"
        out = annotate(pil, text)
        return av.VideoFrame.from_ndarray(np.array(out), format="rgb24")

webrtc_streamer(
    key=st.session_state["webrtc_key"],
    mode=WebRtcMode.SENDRECV,
    media_stream_constraints=MEDIA_STREAM_CONSTRAINTS,
    rtc_configuration=RTC_CONFIGURATION,  # STUN by default; TURN if Twilio creds exist
    video_processor_factory=StageProcessor,
    async_processing=True,                # default behavior
    sendback_audio=False,
    video_html_attrs={"autoPlay": True, "playsinline": True, "muted": True},
)

# Quick check of versions so you know what's actually installed
with st.sidebar:
    try:
        import streamlit_webrtc as stw, aiortc, av as _av
        st.write("webrtc:", stw.__version__)
        st.write("aiortc:", aiortc.__version__)
        st.write("av:", _av.__version__)
    except Exception:
        st.write("webrtc stack: n/a")
